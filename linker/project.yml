title: "Linker Pipeline"
description: "All preprocessing and training to train linker models"
spacy_version: ">=3.2.0,<4.0.0"
# Variables can be referenced across the project.yml using ${vars.var_name}
vars:
  name: "floret_vectors"
  lang: "he"
  oscar_dataset: "unshuffled_deduplicated_en"
  max_texts: 1000
  # number of processes (tokenization) and threads (floret)
  n_process: 8


# These are the directories that the project needs. The project CLI will make
# sure that they always exist.
directories: ["corpus", "vectors", "scripts", "configs", "models"]

## Workflows are sequences of commands (see below) executed in order. You can
## run them via "spacy project run [workflow]". If a commands's inputs/outputs
## haven't changed, it won't be re-run.
workflows:
  all:
    #- download-sefaria-dump
    - export-library
    - train-floret
    - init-floret-vectors

# Project commands, specified in a style similar to CI config files (e.g. Azure
# pipelines). The name is the command name that lets you trigger the command
# via "spacy project run [command] [path]". The help message is optional and
# shown when executing "spacy project run [optional command] [path] --help".
commands:
  - name: "download-sefaria-dump"
    script:
      - "sh scripts/restore_db.sh"
    deps:
      # actually dependent on dump file in Google Cloud...
      - "scripts/restore_db.sh"

  - name: "export-library"
    script:
      - "python scripts/library_exporter.py ${vars.lang} -f both -w corpus/all_text_webpages_he.txt -o corpus/all_text_${vars.lang}"
    deps:
      - "scripts/restore_db.sh"
    outputs:
      - "corpus/all_text_${vars.lang}.txt"
      - "corpus/all_text_${vars.lang}.jsonl"

  - name: "train-floret"
    help: "Train floret vectors"
    script:
      - "python scripts/train_floret.py --model cbow --dim 300 --mincount 10 --minn 3 --maxn 6 --neg 10 --mode floret --hashcount 2 --bucket 20000 --thread ${vars.n_process} --epoch 10 corpus/all_text_${vars.lang}.txt vectors/all_text_${vars.lang}"
    deps:
      - "scripts/train_floret.py"
      - "corpus/all_text_${vars.lang}.txt"
    outputs:
      - "vectors/all_text_${vars.lang}.floret"
      - "vectors/all_text_${vars.lang}.vec"
      - "vectors/all_text_${vars.lang}.bin"

  - name: "init-floret-vectors"
    help: "Create a floret vectors model"
    script:
      - "python -m spacy init vectors ${vars.lang} vectors/all_text_${vars.lang}.floret vectors/all_text_${vars.lang}_floret_model --mode floret"
    deps:
      - "vectors/all_text_${vars.lang}.floret"
    outputs:
      - "vectors/all_text_${vars.lang}_floret_model"

  - name: "pretrain"
    script:
      - "python -m spacy pretrain configs/ref-v3.2.cfg models/pretrain_ref --code ../util/spacy_registry.py --gpu-id 0"
    deps:
      - "configs/ref-v3.2.cfg"
    outputs:
      - "models/pretrain_ref"


