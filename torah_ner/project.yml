title: "Linker Pipeline"
description: "All preprocessing and training for linker models"
spacy_version: ">=3.2.0,<4.0.0"
# Variables can be referenced across the project.yml using ${vars.var_name}
vars:
  name: "ner"
  lang: "he"
  training_input: ""
  config: ""
  annotator_pod: "annotator-bodum-0"
  webpages_dir: "../web_scraper/output"
  embedding_size: 50
  pretrain_model_name: "model8.bin"
  # number of processes (tokenization) and threads (fasttext)
  n_process: 8
  min_training_text_len: 20
  training_percentage: 0.8
  random_seed: 61  # determined to be sufficiently random
  training_input_type: ""


# These are the directories that the project needs. The project CLI will make
# sure that they always exist.
directories: ["corpus", "vectors", "scripts", "configs", "models"]

## Workflows are sequences of commands (see below) executed in order. You can
## run them via "spacy project run [workflow]". If a commands's inputs/outputs
## haven't changed, it won't be re-run.
workflows:
  all:
    - download-sefaria-dump
    - export-library
    - train-fasttext
    - pretrain
    - train-ner-model

# Project commands, specified in a style similar to CI config files (e.g. Azure
# pipelines). The name is the command name that lets you trigger the command
# via "spacy project run [command] [path]". The help message is optional and
# shown when executing "spacy project run [optional command] [path] --help".
commands:
  - name: "download-sefaria-dump"
    script:
      - "sh ../util/restore_db.sh"
    deps:
      # actually dependent on dump file in Google Cloud...
      - "../util/restore_db.sh"

  - name: "export-library"
    script:
      - "python ../util/library_exporter.py ${vars.lang} -f both -w ${vars.webpages_dir} -o corpus/all_text_${vars.lang} -s"
    deps:
      - "../util/restore_db.sh"
    outputs:
      - "corpus/all_text_${vars.lang}.txt"
      - "corpus/all_text_${vars.lang}.jsonl"

  - name: export-training-data
    script:
      - "python ../util/merge_collections.py -o merged_output -c ${vars.training_input}"
      - "python ../util/output_collection_to_docbin.py ${vars.lang} merged_output corpus/${vars.name}_${vars.lang} ${vars.min_training_text_len} ${vars.training_percentage} ${vars.random_seed} ${vars.training_input_type}"

  - name: train-fasttext
    script:
      - "python ../util/embedding_scripts.py fasttext -d ${vars.embedding_size} -i corpus/all_text_${vars.lang}.txt -o vectors/all_text_${vars.lang}.fasttext_${vars.embedding_size}"
      - "python -m spacy init vectors ${vars.lang} vectors/all_text_${vars.lang}.fasttext_${vars.embedding_size}.vec vectors/all_text_${vars.lang}_fasttext_model_${vars.embedding_size}"
    deps:
      - "../util/embedding_scripts.py"
      - "corpus/all_text_${vars.lang}.txt"
    outputs:
      - vectors/all_text_${vars.lang}.fasttext_${vars.embedding_size}.bin
      - vectors/all_text_${vars.lang}.fasttext_${vars.embedding_size}.vec
      - "vectors/all_text_${vars.lang}_fasttext_model_${vars.embedding_size}"

  - name: "pretrain"
    script:
      - "python -m spacy pretrain ${vars.config} models/pretrain_ref_${vars.lang}_${vars.embedding_size} --paths.vectors vectors/all_text_${vars.lang}_fasttext_model_${vars.embedding_size} --paths.raw_text corpus/all_text_${vars.lang}.jsonl --nlp.lang ${vars.lang} --pretraining.objective.hidden_size ${vars.embedding_size} --code ../util/spacy_registry.py --gpu-id 0"
    deps:
      - "${vars.config}"
      - vectors/all_text_${vars.lang}_fasttext_model_${vars.embedding_size}
    outputs:
      - "models/pretrain_ref_${vars.lang}_${vars.embedding_size}"

  - name: "train-ner-model"
    script:
      - "python ../util/merge_collections.py -o merged_output -c ${vars.training_input}"
      - "python -m spacy train ${vars.config} --output models/${vars.name}_${vars.lang} --paths.vectors vectors/all_text_${vars.lang}_fasttext_model_${vars.embedding_size} --paths.train corpus/${vars.name}_${vars.lang}_train.spacy --paths.dev corpus/${vars.name}_${vars.lang}_test.spacy --nlp.lang ${vars.lang} --paths.init_tok2vec models/pretrain_ref_${vars.lang}_${vars.embedding_size}/${vars.pretrain_model_name} --pretraining.objective.hidden_size ${vars.embedding_size} --code ../util/spacy_registry.py --gpu-id 0"
    deps:
      - "${vars.config}"
      - "models/pretrain_ref_${vars.lang}_${vars.embedding_size}"
    outputs:
      - "models/${vars.name}_${vars.lang}"

  - name: "train-blank-pretrained-model"
    script:
      - "python ../util/merge_collections.py -o merged_output -c achronim_output:2"
      - "python -m spacy train ${vars.config} --output models/pretrain_usable --paths.vectors vectors/all_text_${vars.lang}_fasttext_model_${vars.embedding_size} --paths.train corpus/${vars.name}_${vars.lang}_train.spacy --paths.dev corpus/${vars.name}_${vars.lang}_test.spacy --nlp.lang ${vars.lang} --paths.init_tok2vec models/pretrain_ref_${vars.lang}_${vars.embedding_size}/${vars.pretrain_model_name} --training.max_steps 1 --pretraining.objective.hidden_size ${vars.embedding_size} --code ../util/spacy_registry.py --gpu-id 0"
    deps:
      - "${vars.config}"
      - "models/pretrain_ref_${vars.lang}_${vars.embedding_size}"
    outputs:
      - "models/pretrain_usable"
